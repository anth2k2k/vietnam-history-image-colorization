{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import logging"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.set_logical_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.LogicalDeviceConfiguration(memory_limit=3500)]\n",
    "        )\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ],
   "id": "dc6a400333a8258c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "resnet_model = None",
   "id": "8e27510ca2ea8e3e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def build_resnet_model(layer_names):\n",
    "    global resnet_model\n",
    "    if resnet_model is None:\n",
    "        resnet = ResNet50(weights=\"imagenet\", include_top=False)\n",
    "        resnet.trainable = False\n",
    "        outputs = [resnet.get_layer(name).output for name in layer_names]\n",
    "        resnet_model = Model(inputs=resnet.input, outputs=outputs)\n",
    "    return resnet_model"
   ],
   "id": "a9ee4db6364dc597"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def perceptual_loss(y_true, y_pred):\n",
    "    resnet_layers = [\"conv1_relu\", \"conv2_block3_out\", \"conv3_block4_out\"]\n",
    "    resnet_model = build_resnet_model(resnet_layers)\n",
    "    \n",
    "    y_true_lab = tf.concat([tf.zeros_like(y_true[:, :, :, :1]), y_true], axis=-1)\n",
    "    y_pred_lab = tf.concat([tf.zeros_like(y_pred[:, :, :, :1]), y_pred], axis=-1)\n",
    "\n",
    "    y_true_features = resnet_model(y_true_lab)\n",
    "    y_pred_features = resnet_model(y_pred_lab)\n",
    "\n",
    "    loss = tf.reduce_sum([tf.reduce_mean(tf.square(f_true - f_pred)) \n",
    "                          for f_true, f_pred in zip(y_true_features, y_pred_features)])\n",
    "    return loss"
   ],
   "id": "d6ebcb4831cbc5ae"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def build_unet():\n",
    "    inputs = keras.Input(shape=(224, 224, 1))\n",
    "\n",
    "    # Encoder\n",
    "    conv1 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    pool1 = layers.MaxPooling2D((2, 2), strides=2)(conv1)\n",
    "\n",
    "    conv2 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
    "    pool2 = layers.MaxPooling2D((2, 2), strides=2)(conv2)\n",
    "\n",
    "    conv3 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
    "    pool3 = layers.MaxPooling2D((2, 2), strides=2)(conv3)\n",
    "\n",
    "    conv4 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n",
    "    pool4 = layers.MaxPooling2D((2, 2), strides=2)(conv4)\n",
    "\n",
    "    conv5 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n",
    "\n",
    "    # Decoder\n",
    "    up4 = layers.Conv2DTranspose(256, (3, 3), strides=2, padding='same', activation='relu')(conv5)\n",
    "    concat4 = layers.concatenate([up4, conv4])\n",
    "    conv6 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(concat4)\n",
    "\n",
    "    up3 = layers.Conv2DTranspose(128, (3, 3), strides=2, padding='same', activation='relu')(conv6)\n",
    "    concat3 = layers.concatenate([up3, conv3])\n",
    "    conv7 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(concat3)\n",
    "\n",
    "    up2 = layers.Conv2DTranspose(64, (3, 3), strides=2, padding='same', activation='relu')(conv7)\n",
    "    concat2 = layers.concatenate([up2, conv2])\n",
    "    conv8 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(concat2)\n",
    "\n",
    "    up1 = layers.Conv2DTranspose(32, (3, 3), strides=2, padding='same', activation='relu')(conv8)\n",
    "    concat1 = layers.concatenate([up1, conv1])\n",
    "    conv9 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(concat1)\n",
    "\n",
    "    conv10 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n",
    "    outputs = layers.Conv2D(2, (1, 1), activation='tanh', padding='same')(conv10)\n",
    "\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    model.compile(optimizer='adam', loss=perceptual_loss, metrics=['mae'])\n",
    "    return model"
   ],
   "id": "21249cedeb3d972d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "model = build_unet()",
   "id": "85a9a5bea38ae3c3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "model.summary()",
   "id": "4cedf90acb40a54c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def preprocess_image(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "    img = cv2.resize(img, (224, 224))\n",
    "    L, A, B = cv2.split(img)\n",
    "\n",
    "    L = L.astype(\"float32\") / 255.0\n",
    "    A = (A.astype(\"float32\") - 128) / 128.0\n",
    "    B = (B.astype(\"float32\") - 128) / 128.0\n",
    "\n",
    "    return L.reshape(224, 224, 1), np.stack([A, B], axis=-1)"
   ],
   "id": "14f7403e19f4ad7c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "dataset_path = './10k_image'\n",
    "image_paths = [os.path.join(dataset_path, fname) for fname in os.listdir(dataset_path)]"
   ],
   "id": "15ac37a264027a30"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "train_paths, val_paths = train_test_split(image_paths, test_size=0.1, random_state=42)",
   "id": "5fce7c092e6b057"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def data_generator(image_paths, batch_size):\n",
    "    while True:\n",
    "        np.random.shuffle(image_paths)\n",
    "        for i in range(0, len(image_paths), batch_size):\n",
    "            batch_paths = image_paths[i:i+batch_size]\n",
    "            X, Y = zip(*[preprocess_image(img) for img in batch_paths])\n",
    "            yield np.array(X), np.array(Y)"
   ],
   "id": "bcb903c0385bf1c3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "train_gen = data_generator(train_paths, batch_size=8)\n",
    "val_gen = data_generator(val_paths, batch_size=8)"
   ],
   "id": "92e38cab44a0d52"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "checkpoint = keras.callbacks.ModelCheckpoint(\"demo_colorization_model_perceptual_resnet\", save_best_only=True, save_format=\"tf\")\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=3, min_lr=1e-6)\n"
   ],
   "id": "fd9fa22bb87cc6bd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "start_time = time.time()",
   "id": "870ed9a7f1014fe4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "history = model.fit(\n",
    "    train_gen,\n",
    "    steps_per_epoch=len(train_paths) // 8,\n",
    "    validation_data=val_gen,\n",
    "    validation_steps=len(val_paths) // 8,\n",
    "    epochs=30,\n",
    "    callbacks=[checkpoint, reduce_lr]\n",
    ")"
   ],
   "id": "83f26028e5852d49"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def plot_training_history(history):\n",
    "    epochs = range(1, len(history.history['loss']) + 1)\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    # Biểu đồ Loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, history.history['loss'], 'r', label='Training Loss')\n",
    "    plt.plot(epochs, history.history['val_loss'], 'b', label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training & Validation Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # Biểu đồ MAE\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, history.history['mae'], 'r', label='Training MAE')\n",
    "    plt.plot(epochs, history.history['val_mae'], 'b', label='Validation MAE')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('MAE')\n",
    "    plt.title('Training & Validation MAE')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ],
   "id": "4ef70f2c76c0daa1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "plot_training_history(history)",
   "id": "1f7319de3ff61865"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "model.save(\"demo_colorization_model_perceptual_resnet_final\", save_format=\"tf\")",
   "id": "250537f618b97a21"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "end_time = time.time()\n",
    "training_duration = end_time - start_time\n",
    "logging.info(f\"Total training time: {training_duration:.2f} seconds\")"
   ],
   "id": "a7da4c19f3bb8cbc"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
