{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import logging"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.set_logical_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.LogicalDeviceConfiguration(memory_limit=3500)]\n",
    "        )\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ],
   "id": "5f28420548f20dc0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "vgg_model = None",
   "id": "2a9eada503a5cddf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def build_vgg_model(layer_names):\n",
    "    global vgg_model  # Use global model to avoid reloading\n",
    "    if vgg_model is None:\n",
    "        vgg = VGG16(weights=\"imagenet\", include_top=False)\n",
    "        vgg.trainable = False  # Freeze weights\n",
    "        outputs = [vgg.get_layer(name).output for name in layer_names]\n",
    "        vgg_model = Model(inputs=vgg.input, outputs=outputs)\n",
    "    return vgg_model"
   ],
   "id": "1d13d551273744a4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def perceptual_loss(y_true, y_pred):\n",
    "    vgg_layers = [\"block1_conv2\", \"block2_conv2\", \"block3_conv3\"]\n",
    "    vgg_model = build_vgg_model(vgg_layers)\n",
    "\n",
    "    y_true_lab = tf.concat([tf.zeros_like(y_true[:, :, :, :1]), y_true], axis=-1)\n",
    "    y_pred_lab = tf.concat([tf.zeros_like(y_pred[:, :, :, :1]), y_pred], axis=-1)\n",
    "\n",
    "    y_true_features = vgg_model(y_true_lab)\n",
    "    y_pred_features = vgg_model(y_pred_lab)\n",
    "\n",
    "    loss = tf.reduce_sum([tf.reduce_mean(tf.square(f_true - f_pred))\n",
    "                          for f_true, f_pred in zip(y_true_features, y_pred_features)])\n",
    "    return loss"
   ],
   "id": "25dd79d432ec6edc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def build_unet():\n",
    "    inputs = keras.Input(shape=(224, 224, 1))\n",
    "\n",
    "    # Encoder\n",
    "    conv1 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    pool1 = layers.MaxPooling2D((2, 2), strides=2)(conv1)\n",
    "\n",
    "    conv2 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
    "    pool2 = layers.MaxPooling2D((2, 2), strides=2)(conv2)\n",
    "\n",
    "    conv3 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
    "    pool3 = layers.MaxPooling2D((2, 2), strides=2)(conv3)\n",
    "\n",
    "    conv4 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n",
    "    pool4 = layers.MaxPooling2D((2, 2), strides=2)(conv4)\n",
    "\n",
    "    conv5 = layers.Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n",
    "\n",
    "    # Decoder\n",
    "    up4 = layers.Conv2DTranspose(256, (3, 3), strides=2, padding='same', activation='relu')(conv5)\n",
    "    concat4 = layers.concatenate([up4, conv4])\n",
    "    conv6 = layers.Conv2D(256, (3, 3), activation='relu', padding='same')(concat4)\n",
    "\n",
    "    up3 = layers.Conv2DTranspose(128, (3, 3), strides=2, padding='same', activation='relu')(conv6)\n",
    "    concat3 = layers.concatenate([up3, conv3])\n",
    "    conv7 = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(concat3)\n",
    "\n",
    "    up2 = layers.Conv2DTranspose(64, (3, 3), strides=2, padding='same', activation='relu')(conv7)\n",
    "    concat2 = layers.concatenate([up2, conv2])\n",
    "    conv8 = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(concat2)\n",
    "\n",
    "    up1 = layers.Conv2DTranspose(32, (3, 3), strides=2, padding='same', activation='relu')(conv8)\n",
    "    concat1 = layers.concatenate([up1, conv1])\n",
    "    conv9 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(concat1)\n",
    "\n",
    "    conv10 = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n",
    "    outputs = layers.Conv2D(2, (1, 1), activation='tanh', padding='same')(conv10)\n",
    "\n",
    "    model = keras.Model(inputs, outputs)\n",
    "    model.compile(optimizer='adam', loss=perceptual_loss, metrics=['mae'])\n",
    "    return model"
   ],
   "id": "db0c9eb78d5c54e2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "model = build_unet()",
   "id": "4ad32052788ff00f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "model.summary()",
   "id": "6a591351f33fbbed"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def preprocess_image(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "    img = cv2.resize(img, (224, 224))\n",
    "    L, A, B = cv2.split(img)\n",
    "\n",
    "    L = L.astype(\"float32\") / 255.0\n",
    "    A = (A.astype(\"float32\") - 128) / 128.0\n",
    "    B = (B.astype(\"float32\") - 128) / 128.0\n",
    "\n",
    "    return L.reshape(224, 224, 1), np.stack([A, B], axis=-1)"
   ],
   "id": "1083c1340d1d7963"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "dataset_path = './10k_image'\n",
    "image_paths = [os.path.join(dataset_path, fname) for fname in os.listdir(dataset_path)]"
   ],
   "id": "575392efcce5ff83"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "train_paths, val_paths = train_test_split(image_paths, test_size=0.1, random_state=42)",
   "id": "6562f95163a830b2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def data_generator(image_paths, batch_size):\n",
    "    while True:\n",
    "        np.random.shuffle(image_paths)\n",
    "        for i in range(0, len(image_paths), batch_size):\n",
    "            batch_paths = image_paths[i:i+batch_size]\n",
    "            X, Y = zip(*[preprocess_image(img) for img in batch_paths])\n",
    "            yield np.array(X), np.array(Y)"
   ],
   "id": "e13fd96b88183021"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "train_gen = data_generator(train_paths, batch_size=8)\n",
    "val_gen = data_generator(val_paths, batch_size=8)"
   ],
   "id": "23a4d24046956c4f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "checkpoint = keras.callbacks.ModelCheckpoint(\"demo_colorization_model_perceptual\", save_best_only=True, save_format=\"tf\")\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=3, min_lr=1e-6)\n"
   ],
   "id": "73cf93e94fba1300"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "start_time = time.time()",
   "id": "b589d0a8f7e11322"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "history = model.fit(\n",
    "    train_gen,\n",
    "    steps_per_epoch=len(train_paths) // 8,\n",
    "    validation_data=val_gen,\n",
    "    validation_steps=len(val_paths) // 8,\n",
    "    epochs=30,\n",
    "    callbacks=[checkpoint, reduce_lr]\n",
    ")"
   ],
   "id": "db774ad405143931"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def plot_training_history(history):\n",
    "    epochs = range(1, len(history.history['loss']) + 1)\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "\n",
    "    # Biểu đồ Loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, history.history['loss'], 'r', label='Training Loss')\n",
    "    plt.plot(epochs, history.history['val_loss'], 'b', label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training & Validation Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # Biểu đồ MAE\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, history.history['mae'], 'r', label='Training MAE')\n",
    "    plt.plot(epochs, history.history['val_mae'], 'b', label='Validation MAE')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('MAE')\n",
    "    plt.title('Training & Validation MAE')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ],
   "id": "7466e2fc5e82093"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "plot_training_history(history)",
   "id": "b31ff1d00a78ddb7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "model.save(\"demo_colorization_model_perceptual_final\", save_format=\"tf\")",
   "id": "fd934f1d31964ea5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "end_time = time.time()\n",
    "training_duration = end_time - start_time\n",
    "logging.info(f\"Total training time: {training_duration:.2f} seconds\")"
   ],
   "id": "43535d023515f280"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
